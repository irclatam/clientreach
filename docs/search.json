[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The IRC‚Äôs reach in Latin America has increased seven-fold since 2019 [Draft]",
    "section": "",
    "text": "üì¢ In FY24, the IRC reached an estimated 366,300 clients across Latin America.\nOur model indicates that client reach peaked in FY22, but client reach in FY24 was nearly seven times higher than in FY19. Colombia and Venezuela account for the largest numbers, while Ecuador, Peru and El Salvador are notable fast risers. Health services dominate overall support.\n\n\nWhy an estimate, not a count?\nCounting people reached by humanitarian services sounds straightforward. In reality, it rarely is.\nThe IRC‚Äôs first priority is to deliver help, not to collect data or complete paperwork. If someone comes for support but doesn‚Äôt wish to share personal details, we don‚Äôt turn them away. In emergencies, collecting demographic information can be impractical, even unsafe. We don‚Äôt insist on it. This means we can‚Äôt necessarily track whether a given individual who used one service later used another. And because many clients receive more than one type of service‚Äîhealth care, protection, education, or livelihoods‚Äîwe can‚Äôt simply add up service counts. That would inflate the total through double-counting.\nThat does not mean measurement is taken lightly. Instead, the IRC in Latam uses a statistical model built on our Annual Statistics, which track progress across individual services. The model blends these service counts with assumptions about overlap and uncertainty, giving us an estimate of unique clients‚Äîand a way to report how confident we are in that number.\nThe result: in FY24 the IRC reached around 366,300 people in Latin America. Statistically, we are 90% confident the true figure lies between 352,600 and 388,400. (This does not yet include people reached through online or mass-media campaigns such as the Signpost project.)\nThe number is an estimate, but not a guess. It reflects hundreds of thousands of real encounters with people seeking help.\n\n\nHow has the IRC‚Äôs reach changed over time?\nSince FY19, IRC‚Äôs presence in Latin America has increased nearly seven-fold, from 53,800 people to 366,300. Starting in 2019, the IRC‚Äôs footprint was modest, rising to 506,000 in 2022, before tailing off. The latest reach figures, 366,300 per year, represents around 1,000 people receiving a service per day. Figure 1 shows the sharp rise in client numbers.\n\nFigure 1. The IRC‚Äôs reach in Latin America has grown seven-fold since 2019\n\n\n\n\n\nEstimate of the number of clients reach across all countries and service types / sectors, based on IRC Latam's model.The sharp rise reflects expansion across countries and sectors. Figures are the median values generated by the model. Hover over the bars to see the numbers.\n\n\n\n\n\n\nWhere did this happen?\nMuch of this increase has come from the expansion of the IRC‚Äôs presence across different countries. In particular, IRC began working in Venezuela in FY20. The IRC began to work in Ecuador, Peru and Mexico and these also contributed significantly. At the same time, IRC‚Äôs work in Colombia and North Central America ramped up considerably during the period.\n\nFigure 2a. IRC‚Äôs geographic expansionFigure 2b. Health programming drives client growth\n\n\n\n\n\n\n\nEach line represents estimated client reach by country. From FY19 to FY21, North Central America (NCA) was reported as a single country; from FY22 onward, it is disaggregated. Use the legend to toggle countries: click once to show / hide a line, or double-click to isolate a single country.\n\n\n\n\n\n\n\n\n\n\nEach line represents estimated client reach by sector across all countries. Use the legend to toggle sectors: click once to show / hide a line, or double-click to isolate a single sector.\n\n\n\n\n\n\n\n\nCan I see more detail by sector and gender?\nYes! The Annual Statistics is a set of more than 400 figures collected yearly across sectors. Using these figures we can break down the client count by sector and gender. Note that not all indicators are collected by gender. Some indicators are just overall service numbers. This is often the case for informational services, or services like vaccinations. In these cases, the statistical model imputes a gender ratio, based on existing gender ratios at different levels (ie, within a region, within a country, and by sector). Figure 3 shows the average (mean) client count across all simulations, divided by sector, with female, male and total values displayed.\n\nFigure 3. Most clients received health services, and most were women\n\n\n\n\n\nHealth represents the largest number of clients for the IRC in Latin America and a majority of services are delivered to women.\n\n\n\nYou might be thinking, why don‚Äôt the total numbers for each sector add up to the 331,000 clients? That‚Äôs because the total accounts for double counting between sectors, ie, if a single person uses many services. While the Annual Statistics give a breakdown by indicator and sector, it doesn‚Äôt account for double-counting between sectors. That‚Äôs where the model comes into its own, because it models large numbers of scenarios to show what would happen where that overlap is large or small.\n\n\n\nCan you tell me more about how the model works?\nYes! The model doesn‚Äôt directly count clients because this would mean collecting data about all people who receive services. We don‚Äôt want to create barriers to our services, and some people feel uncomfortable sharing their details. In acute emergencies, it can also be logistically challenging to collect this information. Instead, we count the services provided as part of the Annual Statistics process to estimate the number of clients we served.\nUsing these data collected, we run statistical simulations to estimate the total number of clients: around 366,300 clients. But we also give a range‚Äîour best guess is 366,300 and we‚Äôre 90% confident that the number lies between 352,600 and 388,400.\nHow does the statistical model work? We perform simulations to account for various uncertainties in the data, like errors in counting services or people receiving multiple services, or cases where we don‚Äôt collect information on a person‚Äôs gender. We run the simulation over and over to give us realistic scenarios of the total client count if there are small variations in the underlying data and assumptions. The results give us more confidence in the estimate while factoring in things like measurement error and overlaps between different services.\nFigure 4 shows the results of 151 simulations.\n\nFigure 4. The 151 simulation results of the statistical model\n\n\n\n\n\nEach dot is a simulation result of the total clients reached. Each dot represents a different simulation. The black dot is the central estimate, and the yellow ones show a 90% confidence interval. The grey ones are outlier results of the simulations. In other words, they are less likely to be the true value. The true value is most likely the median, but we are almost certain it falls within the range of the yellow dots.\n\n\n\n\nThose are the results of the full model for Latin America. But since the Annual Statistics are collected by country, we can also show the results at a country level. Figure 5 shows the range of estimates generated for each country.\n\n\nFigure 5. Client reach in FY24 varies by country, with uncertainty ranges shown\n\n\n\n\n\nNote: In FY24, more clients were reached in El Salvador and Venezuela. This chart shows the central estimate for each country (the dot) as well as the plausible range of values (the thin line is the 95% confidence interval and the thick line is the 66% confidence interval). The text shows the median, or central estimate (ie, the value shown by the dot).\n\n\n\n\n\n\n\nFor those looking for more technical details\nThe IRC doesn‚Äôt count each client individually. Instead, we track service deliveries, but we recognise that some clients receive multiple services, which could lead to an overcount. And that we maybe didn‚Äôt count everything correctly, which could lead to an undercount. To avoid this, we use a statistical model to simulate different scenarios that account for potential sources of uncertainty.\n\nUncertainty about the precision of service counts. We assume there could be small errors in how services are counted. For example, sometimes data collection might be incomplete or inaccurate due to limitations in reporting systems or challenges in fieldwork. There might also be small inconsistencies in the way that data are collected from location to location.\nCases where gender of service recipients isn‚Äôt recorded. In some cases we collect and record demographic data on gender from clients. In others we don‚Äôt. We therefore have to estimate this breakdown in that subset of cases.\nInterventions that target households, rather than individuals. Some interventions under Economic Recovery & Development are delivered at the household level rather than to individuals. Estimating the number of people reached can be challenging when only one household member is recorded as the recipient. To address this, we use statistical modeling to estimate household size and distribute reach across household members.\nUncertainty about the reach of health programming. This is where we face significant uncertainty. While we know the number of people potentially eligible for health services (the catchment area where we operate), it‚Äôs difficult to know exactly how many people actually receive them. We also directly count some health services but not all. If someone drops-in for a reproductive health information session, we might not note that down. People might also drop out of programs, move, or not report their participation. To account for this uncertainty, we simulate different scenarios using a statistical approach that helps us estimate the range of potential values for the number of people who were truly reached.\nOverlap between service areas. Since many clients use multiple services (eg, a person might receive both education and health services), we need to account for this overlap. If we simply added up the people receiving each service, we‚Äôd risk double-counting the same individuals. Our models simulate how much overlap is likely and adjust for it. In this case, we estimate that around 51% of the total population (on average) may have received more than one type of service. We randomly vary this percentage to get a sense of potential sensitivity of our overall calculations to changes in this percentage.\n\nStep-by-step model explanation\nFor each country and indicator, we simulate small variations multiple times, using different probability distributions. This process helps to show how sensitive the country totals are to the potential errors and measurement issues described above. The model implements the following workflow.\n\nStep 1. Adjusting service counts. In Step 1, we adjust the indicator data by factoring in the regional averages for services, smoothing out any large discrepancies. This helps us reduce errors that could arise due to incomplete or inconsistent data across different countries or regions. For example, we use a blending weight to adjust the numbers closer to regional norms, which helps us account for country-specific biases or gaps, and we vary the blending weight using a normal probability distribution.\nStep 2. Estimate gender breakdown where gender was not recorded. For some indicators we know the male / female breakdown, for others we don‚Äôt. For each indicator where it‚Äôs not known we estimate it. This is done by creating a weighted average of three gender ratios: the country gender ratio, the regional ratio and the sector ratio. In each simulation, a random weight is applied to each of these ratios, and the average of those ratios is then used to estimate male and female clients, per indicator. This means that in each simulation the gender numbers are different.\nStep 3. Estimate household size for economic wellbeing indicators. We use UNFPA country-level figures as a baseline for household size. For each indicator in each simulation, we randomly generate a household size using a Poisson distribution with lambda set to the UNFPA figure. We then multiply the indicator value by the simulated household size to estimate total reach, distributing the additional household members evenly by gender.\nFor example, if a female recipient receives a household-level cash grant and the simulated household size is five, we record five people reached. Subtracting the known recipient, we apportion the remaining four as two males and two females. Thus, the total reach for that household would be three women and two men. If the recipient were male in a household of nine, we would record five males and four females.\nStep 4. Estimate plausible values for health reach. In Step 4, we use a logarithmic weighting function to adjust health service reach estimates based on the ratio of directly measured health services to the catchment area. For each simulation, this function compares the health catchment number with the total number of services, and asks the question, are these numbers consistent? The function assigns a weight that determines how much we should rely on observed service counts versus the total population in the catchment area.\n\n‚Å†Low health presence ‚Üí The model relies more on observed service counts.\nHigh health presence ‚Üí The model shifts the estimate toward the total population.\n\nThis transformation ensures that service reach estimates don‚Äôt unrealistically overshoot when observed counts are high, while still adjusting upward when observed counts are low relative to population size. The use of a logarithmic function is key here because it smoothly scales the weight rather than applying a hard cutoff, ensuring a more gradual transition between low and high service presence scenarios.\nStep 5. Monte Carlo simulations. Monte Carlo simulations are a technique used to model uncertainty and explore different possible outcomes when there are many uncertain variables. In the context of our model, in Step 5 we use Monte Carlo simulations to generate a wide range of plausible values for our final estimates. Monte Carlo simulations let us explore many different possible scenarios, based on real-world uncertainty, and generate a more accurate and reliable range for the number of clients served.\n\nBy combining these methods‚Äîadjusting for service count uncertainties, imputing gender, modeling household size, using logarithmic functions to better handle skewed data, and running Monte Carlo simulations to account for uncertainty‚Äîwe can make more informed estimates and better understand the reach and impact of our services. The simulations give us confidence that the range we report (eg, 352,600 to 388,400) reflects a wide range of possible real-world outcomes, and not just a single estimate.\n\n\nFurther information and resources\nIf you have questions about the data, the methodology, or client reach more generally within Latin America, please email:\n\nPhilip Blue, Regional Measurement Adviser, Latam\nKatie Susman, Deputy Regional Director, Latam\nMark Montague, Deputy Director, MEAL\n\nFor more about the Annual Statistics, see the Rescuenet page or dashboard.\nData for all 151 simulations can be downloaded here."
  }
]